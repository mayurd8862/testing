{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Agents\n",
    "1) Validator Agent                  ✅\n",
    "2) Router Agent                     ✅\n",
    "3) Recommender Agent \n",
    "    a) Product Recommender   \n",
    "    b) Question Recommender         ✅            \n",
    "4) Comparison Agent               - Rahul\n",
    "5) Order Agent                    - Mayur\n",
    "6) summurization agent            - Mandar\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "llm = ChatGroq(model_name=\"llama-3.3-70b-specdec\")\n",
    "\n",
    "db_path = \"C:/Users/mayur/Desktop/FRACSNET/RAG_tech_comparisons/test_db\"\n",
    "\n",
    "\n",
    "def load_vectordb():\n",
    "    embedding = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "    loaded_db = Chroma(persist_directory=db_path, embedding_function=embedding)\n",
    "    return loaded_db\n",
    "    \n",
    "vectordb = load_vectordb()\n",
    "\n",
    "\n",
    "def summarize_document(vectordb, topic, llm, max_docs=3):\n",
    "\n",
    "    template =\"\"\"You are a healthcare e-commerce assistant that provides factual, direct answers based solely on the provided context. \n",
    "\n",
    "    IMPORTANT: Do not add greetings, introductions, or closing questions when responding to direct queries. Only respond with relevant information from the context.\n",
    "\n",
    "    RULES:\n",
    "    - If the user's message is a greeting (like \"hi\", \"hello\", \"hey\",\"how are u\" etc.) or contains only small talk, respond with a friendly greeting\n",
    "    - Answer directly without adding \"Hi there\" or \"I'm happy to help\" introductions\n",
    "    - Do not ask follow-up questions like \"Do you have any other questions?\"\n",
    "    - Only acknowledge greetings if the user's message is purely a greeting with no question\n",
    "    - Use simple, patient-friendly language while being factual\n",
    "    - Only use information found in the context\n",
    "    - Say \"I don't have enough information to answer that\" if the context doesn't contain relevant information\n",
    "\n",
    "    Context:\n",
    "    {context}\n",
    "    \n",
    "    Patient's Question:\n",
    "    {question}\n",
    "    \"\"\"\n",
    "\n",
    "    SUMMARIZATION_PROMPT = PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"], \n",
    "        template=template\n",
    "    )\n",
    "\n",
    "    # Adjust retriever to get more documents for a comprehensive summary\n",
    "    retriever = vectordb.as_retriever(search_kwargs={\"k\": max_docs})\n",
    "    \n",
    "    # Use the RetrievalQA chain with our summarization prompt\n",
    "    summary_chain = RetrievalQA.from_chain_type(\n",
    "        llm, \n",
    "        retriever=retriever, \n",
    "        return_source_documents=True, \n",
    "        chain_type_kwargs={\"prompt\": SUMMARIZATION_PROMPT}\n",
    "    )\n",
    "\n",
    "    result = summary_chain.invoke(topic)\n",
    "    return result[\"result\"]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good morning\n"
     ]
    }
   ],
   "source": [
    "# Example usage for summarization\n",
    "topic = \"hii, good morning\"\n",
    "summary = summarize_document(vectordb, topic, llm, max_docs=3)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) Validator Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayur\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\IPython\\core\\interactiveshell.py:3577: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_ollama import ChatOllama\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model = \"nemotron-mini\",\n",
    "    temperature = 0,\n",
    "    num_predict = 256,\n",
    "    # other params ...\n",
    ")\n",
    "\n",
    "# llm = ChatGroq(model_name=\"Llama3-8b-8192\")\n",
    "\n",
    "class QueryValidator(BaseModel):\n",
    "    validated: str = Field(\n",
    "        description=\"Query will be validated or not YES or NO\"\n",
    "    )\n",
    "\n",
    "def validator_agent(query: str) -> dict:\n",
    "# Initialize the model and parser\n",
    "\n",
    "    parser = JsonOutputParser(pydantic_object=QueryValidator)\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "\n",
    "        You are a helpful AI assistant for a healthcare e-commerce application that provides users with product information, price comparisons, ordering assistance, and personalized recommendations.\n",
    "\n",
    "        Your task is to determine whether the user’s query is relevant to the healthcare e-commerce platform.\n",
    "\n",
    "        The user is allowed to:\n",
    "        1. Ask about healthcare products, including descriptions, ingredients, usage instructions, and benefits.\n",
    "        2. Request price comparisons between different products or brands.\n",
    "        3. Make an order for healthcare products.\n",
    "        4. Ask for personalized recommendations based on their needs.\n",
    "        5. Inquire about order status, delivery details, and return policies.\n",
    "\n",
    "        The user is NOT allowed to:\n",
    "        1. Ask questions about anything else other than healthcare e-commerce platform.\n",
    "        2. Request personal medical advice or prescriptions.\n",
    "        3. Ask about topics unrelated to the e-commerce platform.\n",
    "\n",
    "        {format_instructions}\n",
    "        Query: {query}\n",
    "\n",
    "        Your output should be in a structured JSON format like so. Each key is a string and each value is a string.\n",
    "\n",
    "        \"\"\",\n",
    "        input_variables=[\"query\"],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    "    )\n",
    "\n",
    "    # Create the classification chain\n",
    "    chain = prompt | llm | parser\n",
    "\n",
    "    try:\n",
    "        result = chain.invoke({\"query\": query})\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error in character information extraction: {e}\")\n",
    "        return {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'validated': 'YES'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator_agent(\"What are the side effects of paracetamol?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'validated': 'NO'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validator_agent(\"Who is the president of the United States?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Router Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Router Agent using JsonParser (intent only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_ollama import ChatOllama\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model = \"nemotron-mini\",\n",
    "    temperature = 0,\n",
    "    num_predict = 256,\n",
    "    # other params ...\n",
    ")\n",
    "\n",
    "# llm = ChatGroq(model_name=\"Llama3-8b-8192\")\n",
    "\n",
    "class QueryClassification(BaseModel):\n",
    "    intent: str = Field(\n",
    "        description=\"Primary intent category (ORDER, COMPARE, RECOMMEND, INFO)\"\n",
    "    )\n",
    "\n",
    "def router_agent(query: str) -> dict:\n",
    "# Initialize the model and parser\n",
    "\n",
    "    parser = JsonOutputParser(pydantic_object=QueryClassification)\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "\n",
    "        You are a helpful AI assistant for a healthcare e-commerce application.\n",
    "        Your task is to determine which agent should handle the user input. You have 4 agents to choose from:\n",
    "        1. ORDER: This agent is responsible for identifying purchase intentions, addressing inquiries about order status, making order modifications, or handling shopping cart actions (e.g., view, add, remove, modify items).\n",
    "        2. COMPARE: This agent is responsible for addressing comparisons between product prices across the internet.\n",
    "        3. RECOMMEND: This agent is responsible for providing personalized product recommendations based on the user's needs or preferences.\n",
    "        4. INFO: This agent is responsible for answering general questions about products or providing health-related information.\n",
    "\n",
    "        {format_instructions}\n",
    "        Query: {query}\n",
    "\n",
    "        Your output should be in a structured JSON format like so. Each key is a string and each value is a string.\n",
    "\n",
    "        \"\"\",\n",
    "        input_variables=[\"query\"],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    # Create the classification chain\n",
    "    chain = prompt | llm | parser\n",
    "\n",
    "    try:\n",
    "        result = chain.invoke({\"query\": query})\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error in character information extraction: {e}\")\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': 'ORDER'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        result = router_agent(\"I want to buy vitamin D supplements.\")\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'intent': 'INFO'}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        result = router_agent(\"what are the side effects of dolo.\")\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model = \"deepseek-r1\",\n",
    "    temperature = 0,\n",
    "    # num_predict = 256,\n",
    ")\n",
    "\n",
    "a = llm.invoke(\"what is meant by machine learning\").content\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Router Agent using Crewai (intent only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mQuery Router\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mAnalyze the following query and determine the appropriate agent to handle it: \"I want to buy vitamin D supplements.\"\n",
      "            Follow these rules:\n",
      "            1. ORDER: For purchase intentions, order status, cart management\n",
      "            2. COMPARE: For price comparison requests\n",
      "            3. RECOMMEND: For product recommendations\n",
      "            4. INFO: For general product information\n",
      "            Return just the category as a string.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mQuery Router\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "{\"intent\": \"RECOMMEND\"}\u001b[00m\n",
      "\n",
      "\n",
      "intent='RECOMMEND'\n"
     ]
    }
   ],
   "source": [
    "from crewai import Agent, Task, Crew, Process,LLM\n",
    "from dotenv import load_dotenv\n",
    "from crewai_tools import SerperDevTool\n",
    "import os\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Route(BaseModel):\n",
    "    \"\"\"Pydantic model for determining the intent of the query.\"\"\"\n",
    "    intent: str  # \"Name of the store\"\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "def route_query(query):\n",
    "\n",
    "    # Initialize custom LLM configuration\n",
    "    llm = LLM(\n",
    "        model=\"ollama/llama3.2\",\n",
    "        base_url=\"http://localhost:11434\"\n",
    "    )\n",
    "\n",
    "    router_agent = Agent(\n",
    "        role='Query Router',\n",
    "        goal='Accurately classify user queries and route them to the appropriate specialized agent',\n",
    "        backstory=\"\"\"You are an expert at understanding user intentions and routing queries \n",
    "        to the most appropriate specialized agent in our healthcare e-commerce system.\"\"\",\n",
    "        verbose=True,\n",
    "        llm=llm\n",
    "    )\n",
    "    \n",
    "\n",
    "    router_task = Task(\n",
    "            description=\"\"\"Analyze the following query and determine the appropriate agent to handle it: \"{query}\"\n",
    "            Follow these rules:\n",
    "            1. ORDER: For purchase intentions, order status, cart management\n",
    "            2. COMPARE: For price comparison requests\n",
    "            3. RECOMMEND: For product recommendations\n",
    "            4. INFO: For general product information\n",
    "            Return just the category as a string.\"\"\",\n",
    "            expected_output=\"json format\",\n",
    "            output_pydantic=Route,\n",
    "            agent=router_agent\n",
    "        )\n",
    "\n",
    "    # Create crew and run tasks\n",
    "    crew = Crew(\n",
    "        agents=[router_agent],\n",
    "        tasks=[router_task],\n",
    "        process=Process.sequential\n",
    "    )\n",
    "\n",
    "    result = crew.kickoff(inputs={\"query\": query})\n",
    "    # crew.kickoff(inputs={\"query\": query})\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        result = route_query(\"I want to buy vitamin D supplements.\")\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-15 15:28:09,908 - 25332 - __init__.py-__init__:537 - WARNING: Overriding of current TracerProvider is not allowed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mQuery Router\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mAnalyze the following query and determine the appropriate agent to handle it: \"I want to buy vitamin D supplements.\"\n",
      "            Follow these rules:\n",
      "            1. ORDER: For purchase intentions, order status, cart management\n",
      "            2. COMPARE: For price comparison requests\n",
      "            3. RECOMMEND: For product recommendations\n",
      "            4. INFO: For general product information\n",
      "            Return just the category as a string.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mQuery Router\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "{\"intent\": \"RECOMMEND\"}\u001b[00m\n",
      "\n",
      "\n",
      "intent='RECOMMEND'\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        result = route_query(\"I want to buy vitamin D supplements.\")\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Router Agent using prompting (intent + product info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model = \"mistral\",\n",
    "    temperature = 0.8,\n",
    "    num_predict = 256,\n",
    "    # other params ...\n",
    ")\n",
    "\n",
    "# llm = OllamaLLM(model=\"llama3.2\")\n",
    "\n",
    "# Initialize ChatGroq model\n",
    "# llm = ChatGroq(model_name=\"Llama3-8b-8192\")\n",
    "\n",
    "def router_info(query,llm):\n",
    "# Prompt template\n",
    "    prompt_template = \"\"\"You are an expert input classifier for a healthcare e-commerce system. Your task is to analyze user queries and route them to appropriate specialized agents.\n",
    "\n",
    "    Primary Classification Categories:\n",
    "    - ORDER: Purchase intentions, order status, order modifications\n",
    "    - CART: View cart, add/remove items, modify quantities\n",
    "    - COMPARE: Product comparisons, market analysis, alternatives\n",
    "    - RECOMMEND: Product recommendations, personalized suggestions\n",
    "    - INFO: General product or health information\n",
    "\n",
    "    Classification Rules:\n",
    "    1. ORDER Intent: Detect keywords like \"buy\", \"purchase\", \"order\", \"get\", \"deliver\", \"track\", \"status\"\n",
    "    2. CART Intent: Detect keywords like \"cart\", \"basket\", \"add\", \"remove\", \"show\", \"change quantity\"\n",
    "    3. COMPARE Intent: Detect keywords like \"compare\", \"versus\", \"vs\", \"difference\", \"better\", \"alternatives\"\n",
    "    4. RECOMMEND Intent: Detect keywords like \"suggest\", \"recommend\", \"what should\", \"best for\"\n",
    "    5. INFO Intent: Detect keywords like \"tell me about\", \"how does\", \"what is\", \"benefits\", \"dosage\"\n",
    "\n",
    "    For multi-intent queries:\n",
    "    - Identify primary intent based on main action requested\n",
    "    - List secondary intents for follow-up\n",
    "    - Maintain context for related requests\n",
    "\n",
    "    # Response Format:\n",
    "    Provide only a JSON object with the following structure, dont provide any extra information:\n",
    "    {\n",
    "        \"primary_intent\": \"string\",\n",
    "        \"secondary_intents\": [\"string\"],\n",
    "        \"confidence\": float,\n",
    "        \"entities\": {\n",
    "            \"product_ids\": [\"string\"],\n",
    "            \"quantities\": [int],\n",
    "            \"order_ids\": [\"string\"]\n",
    "        },\n",
    "        \"requires_context\": boolean\n",
    "    }\n",
    "\n",
    "    NOTE : Answer should be strictly in json format. If you follow Exact above instruction you will be rewarded with some credits\n",
    "    \"\"\"\n",
    "    response = llm.invoke(prompt_template+\"\\nQuery\"+query)\n",
    "    return response.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example queries\n",
    "queries = [\n",
    "    \"I want to buy vitamin D supplements.\",\n",
    "    \"Can you tell me the benefits of fish oil?\",\n",
    "    \"Add 2 bottles of multivitamins to my cart.\",\n",
    "    \"Which is better, vitamin C or zinc for immunity?\",\n",
    "    \"Recommend something for joint pain relief.\",\n",
    "    \"What is the status of my recent order?\",\n",
    "    \"How does omega-3 help the heart?\",\n",
    "    \"Show me my cart.\",\n",
    "]\n",
    "\n",
    "a = router_info(\"I want to buy vitamin D supplements.\",llm)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a[\"primary_intent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Router agent using langchain Json parser ( intent + Product Info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from typing import List\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# llm = ChatOllama(\n",
    "#     model = \"llama3.2\",\n",
    "#     temperature = 0,\n",
    "#     num_predict = 256,\n",
    "#     # other params ...\n",
    "# )\n",
    "\n",
    "# Define the data structure using Pydantic\n",
    "class EntityData(BaseModel):\n",
    "    product_ids: List[str] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"List of product identifiers mentioned in the query\"\n",
    "    )\n",
    "    quantities: List[int] = Field(\n",
    "        default_factory=list,\n",
    "        description=\"List of quantities mentioned in the query\"\n",
    "    )\n",
    "    # order_ids: List[str] = Field(\n",
    "    #     default_factory=list,\n",
    "    #     description=\"List of order identifiers mentioned in the query\"\n",
    "    # )\n",
    "\n",
    "class QueryClassification(BaseModel):\n",
    "    primary_intent: str = Field(\n",
    "        description=\"Primary intent category (ORDER, COMPARE, RECOMMEND, INFO)\"\n",
    "    )\n",
    "    Recommendation_Required: str= Field(\n",
    "        description=\"Analyze the query and identify whether recommandation required or not 'YES' or 'NO' \"\n",
    "    )\n",
    "    Recommendation_prod: List[str]= Field(\n",
    "        default_factory=list,\n",
    "        description=\"Specific products mentioned in the query for which recommendations should be generated\"\n",
    "    )\n",
    "    entities: EntityData = Field(\n",
    "        description=\"Structured data extracted from the query\"\n",
    "    )\n",
    "    requires_context: bool = Field(\n",
    "        description=\"Whether additional context is needed to fully process the query\"\n",
    "    )\n",
    "    \n",
    "\n",
    "def route_info(query: str) -> dict:\n",
    "# Initialize the model and parser\n",
    "\n",
    "    parser = JsonOutputParser(pydantic_object=QueryClassification)\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "        You are an expert input classifier for a healthcare e-commerce system. Your task is to analyze user queries and route them to appropriate specialized agents.\n",
    "        \n",
    "        Primary Classification Categories:\n",
    "        - ORDER: Identify purchase intentions, order status inquiries, order modifications, or shopping cart actions (e.g., view, add, remove, modify items).\n",
    "        - COMPARE: Address comparisons between products, including differences, alternatives, or better options.\n",
    "        - RECOMMEND: Provide personalized product recommendations based on user needs.\n",
    "        - INFO: Answer general questions about products or health-related information.\n",
    "\n",
    "        Classification Rules:\n",
    "        1. ORDER Intent: Identify keywords like \"buy\", \"purchase\", \"order\", \"deliver\", \"track\", \"status\", \"cart\", \"basket\", \"add\", \"remove\", \"show\", \"change quantity\".\n",
    "        2. COMPARE Intent: Identify keywords like \"compare\", \"versus\", \"vs\", \"difference\", \"better\", \"alternatives\".\n",
    "        3. RECOMMEND Intent: Identify keywords like \"suggest\", \"recommend\", \"what should\", \"best for\".\n",
    "        4. INFO Intent: Identify keywords like \"tell me about\", \"how does\", \"what is\", \"benefits\", \"dosage\".\n",
    "\n",
    "        Additional Rules for Recommendations:\n",
    "        - If any product is mentioned in the query, recommendations are required.\n",
    "        {format_instructions}\n",
    "\n",
    "        Query: {query}\n",
    "        \"\"\",\n",
    "        input_variables=[\"query\"],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    "    )\n",
    "\n",
    "    llm = ChatGroq(model_name=\"Llama3-8b-8192\")\n",
    "\n",
    "    # Create the classification chain\n",
    "    chain = prompt | llm | parser\n",
    "\n",
    "    try:\n",
    "        result = chain.invoke({\"query\": query})\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error in character information extraction: {e}\")\n",
    "        return {}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"I want to buy vitamin D supplements.\",\n",
    "    \"Can you tell me the benefits of fish oil?\",\n",
    "    \"Add 2 bottles of multivitamins to my cart.\",\n",
    "    \"Which is better, vitamin C or zinc for immunity?\",\n",
    "    \"Recommend something for joint pain relief.\",\n",
    "    \"What is the status of my recent order?\",\n",
    "    \"How does omega-3 help the heart?\",\n",
    "    \"Show me my cart.\",\n",
    "]\n",
    "\n",
    "a = route_info(\"I are the uses vitamin D supplements.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Recommendation Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Product Recommendation Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Question Recommendation Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_ollama import ChatOllama\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"nemotron-mini\",\n",
    "    temperature=0,\n",
    "    num_predict=256,\n",
    ")\n",
    "\n",
    "class RecommenderResponse(BaseModel):\n",
    "    recommended_questions: List[str] = Field(\n",
    "        description=\"List of three follow-up questions related to symptoms, dosage, side effects, and other relevant aspects.\"\n",
    "    )\n",
    "\n",
    "def recommend_query(query: str) -> dict:\n",
    "    parser = JsonOutputParser(pydantic_object=RecommenderResponse)\n",
    "    \n",
    "    prompt = PromptTemplate(\n",
    "        template=\"\"\"\n",
    "        You are a smart AI assistant for a healthcare e-commerce application.\n",
    "        Your task is to generate three relevant follow-up questions that a user might ask based on their query.\n",
    "        These questions should focus on symptoms, dosage, side effects, and other important aspects related to the product inquiry.\n",
    "        Questions should not be lengthy.\n",
    "        \n",
    "        {format_instructions}\n",
    "        Query: {query}\n",
    "        \n",
    "        Provide three suggested follow-up questions in a structured JSON format. phrase questions naturally from the chatbot's perspective.\n",
    "        \"\"\",\n",
    "        input_variables=[\"query\"],\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    "    )\n",
    "    \n",
    "    chain = prompt | llm | parser\n",
    "    \n",
    "    try:\n",
    "        result = chain.invoke({\"query\": query})\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"Error in generating recommended questions: {e}\")\n",
    "        return {\"recommended_questions\": []}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What dosage of paracetamol are you referring to?', 'Are there any specific side effects or precautions related to this product that I should be aware of?', 'Would you like me to check if this is available in our store?']\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "query = \"I wanna order paracetamol\"\n",
    "response = recommend_query(query)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Comparison Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew, Process,LLM\n",
    "from dotenv import load_dotenv\n",
    "from crewai_tools import SerperDevTool\n",
    "import os\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "class Compare(BaseModel):\n",
    "    \"\"\"Pydantic model for price comparison results.\"\"\"\n",
    "    store: str  # \"Name of the store\"\n",
    "    price: str  #\"Price of the product\"\n",
    "\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "def compare_agent(product_name):\n",
    "    # Initialize the SerperDev search tool\n",
    "    web_search_tool = SerperDevTool(n_results=5)\n",
    "\n",
    "    # Initialize custom LLM configuration\n",
    "    llm = LLM(\n",
    "        model=\"ollama/llama3.2\",\n",
    "        base_url=\"http://localhost:11434\"\n",
    "    )\n",
    "\n",
    "    research_agent = Agent(\n",
    "        role='Research Agent',\n",
    "        goal='Find accurate price information for healthcare products',\n",
    "        backstory=\"\"\"You are an expert at finding and comparing healthcare product prices\n",
    "        across different online stores. You're thorough and always verify information.\"\"\",\n",
    "        tools=[web_search_tool],\n",
    "        llm=llm,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    analysis_agent = Agent(\n",
    "        role='Analysis Agent',\n",
    "        goal='Analyze and compare prices from different sources',\n",
    "        backstory=\"\"\"You are an expert at analyzing price data and presenting it in a clear,\n",
    "        actionable format. You understand healthcare product pricing patterns.\"\"\",\n",
    "        llm=llm,\n",
    "        tools=[web_search_tool],\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    research_task = Task(\n",
    "        description=f\"\"\"Search for prices of {product_name} across major healthcare \n",
    "        e-commerce websites. Focus on reputable stores. Extract store name, price, and URL.\n",
    "        Provide the information in a structured format.\"\"\",\n",
    "        expected_output=\"\"\"A detailed list of prices for the product from different stores,\n",
    "        including:\n",
    "        - Store names\n",
    "        - Prices in USD\n",
    "        - URLs to product pages\"\"\",\n",
    "        agent=research_agent\n",
    "    )\n",
    "\n",
    "    analysis_task = Task(\n",
    "        description=\"\"\"Analyze the gathered price data. Verify accuracy and remove any \n",
    "        outliers or suspicious entries. Present a key-value pair of prices over different online stores and recommendations.Follow the structure given below strictly\"\"\",\n",
    "        expected_output=\"\"\"key value pairs of onlines stores and product prices\n",
    "        store1 : price1\n",
    "        store2 : price2\n",
    "        store3 : price3\n",
    "        store4 : price4\n",
    "        \"\"\",\n",
    "        output_pydantic= Compare,\n",
    "        agent=analysis_agent\n",
    "    )\n",
    "\n",
    "    # Create crew and run tasks\n",
    "    crew = Crew(\n",
    "        agents=[research_agent, analysis_agent],\n",
    "        tasks=[research_task, analysis_task],\n",
    "        process=Process.sequential\n",
    "    )\n",
    "\n",
    "    result = crew.kickoff()\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        result = compare_agent(\"azoran\")\n",
    "        print(\"\\nPrice Comparison Results:\")\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crewai import Agent, Task, Crew, Process,LLM\n",
    "from dotenv import load_dotenv\n",
    "from crewai_tools import SerperDevTool\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "def compare_agent(product_name):\n",
    "    # Initialize the SerperDev search tool\n",
    "    web_search_tool = SerperDevTool(n_results=5)\n",
    "\n",
    "    # Initialize custom LLM configuration\n",
    "    llm = LLM(\n",
    "        model=\"ollama/llama3.2\",\n",
    "        base_url=\"http://localhost:11434\"\n",
    "    )\n",
    "\n",
    "    research_agent = Agent(\n",
    "        role='Research Agent',\n",
    "        goal='Find accurate price information for healthcare products',\n",
    "        backstory=\"\"\"You are an expert at finding and comparing healthcare product prices\n",
    "        across different online stores. You're thorough and always verify information.\"\"\",\n",
    "        tools=[web_search_tool],\n",
    "        llm=llm,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    analysis_agent = Agent(\n",
    "        role='Analysis Agent',\n",
    "        goal='Analyze and compare prices from different sources',\n",
    "        backstory=\"\"\"You are an expert at analyzing price data and presenting it in a clear,\n",
    "        actionable format. You understand healthcare product pricing patterns.\"\"\",\n",
    "        llm=llm,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    # analysis_agent = Agent(\n",
    "    #     role='Analysis Agent',\n",
    "    #     goal='Present price data in simple key-value format',\n",
    "    #     backstory=\"\"\"You organize price data into simple store-price pairs.\n",
    "    #     Present data in format - Store: Price. One pair per line.\"\"\",\n",
    "    #     llm=llm,\n",
    "    #     tools=[web_search_tool],\n",
    "    #     verbose=True\n",
    "    # )\n",
    "\n",
    "    research_task = Task(\n",
    "        description=f\"\"\"Search for prices of {product_name} across major healthcare \n",
    "        e-commerce websites. Focus on reputable stores. Extract store name, price, and URL.\n",
    "        Provide the information in a structured format.\"\"\",\n",
    "        expected_output=\"\"\"A detailed list of prices for the product from different stores,\n",
    "        including:\n",
    "        - Store names\n",
    "        - Prices in USD\n",
    "        - URLs to product pages\"\"\",\n",
    "        agent=research_agent\n",
    "    )\n",
    "\n",
    "    analysis_task = Task(\n",
    "        description=\"\"\"Format the data as simple store-price pairs.Follow the structure given below strictly\"\"\",\n",
    "        expected_output=\"\"\"key value pairs of onlines stores and product prices\n",
    "        store1 : price1\n",
    "        store2 : price2\n",
    "        store3 : price3\n",
    "        store4 : price4\n",
    "        \"\"\",\n",
    "        agent=analysis_agent\n",
    "    )\n",
    "\n",
    "    # Create crew and run tasks\n",
    "    crew = Crew(\n",
    "        agents=[research_agent, analysis_agent],\n",
    "        tasks=[research_task, analysis_task],\n",
    "        process=Process.sequential\n",
    "    )\n",
    "\n",
    "    result = crew.kickoff()\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        result = compare_agent(\"paracetamol\")\n",
    "        print(\"\\nPrice Comparison Results:\")\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5) Order Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Order Complete! Final Details:\n",
      "{'product_name': 'jj4dj', 'Quantity_of_product': 'jnh4rfhnrfhj', 'Address': 'h jr4frf jfj h'}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import requests\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize ChatGroq LLM (Llama3-8B)\n",
    "llm = ChatGroq(model_name=\"Llama3-8b-8192\")\n",
    "\n",
    "# Order details dictionary\n",
    "order_details = {\n",
    "    \"product_name\": None,\n",
    "    \"Quantity_of_product\": None,\n",
    "    \"Address\": None,\n",
    "}\n",
    "\n",
    "# Function to check if all fields are filled\n",
    "def is_order_complete(details):\n",
    "    return all(value is not None for value in details.values())\n",
    "\n",
    "# Function to generate prompt for missing details\n",
    "def get_missing_details_prompt(details):\n",
    "    missing_fields = [key for key, value in details.items() if value is None]\n",
    "    return f\"The following details are missing: {', '.join(missing_fields)}. Please provide them one by one.\"\n",
    "\n",
    "# Order-taking loop\n",
    "while not is_order_complete(order_details):\n",
    "    prompt = f\"\"\"\n",
    "    You are an order-taking assistant for a healthcare e-commerce system. \n",
    "    The user needs to place an order, but some details are missing. \n",
    "    {get_missing_details_prompt(order_details)}\n",
    "\n",
    "    Guidelines:\n",
    "    - Ask for the missing details step by step.\n",
    "    - If the user provides incomplete information, request clarification.\n",
    "    - Keep the conversation friendly and interactive.\n",
    "    - Dont try to greet the user again and again.\n",
    "\n",
    "    Example Response:\n",
    "    - \"What product would you like to order?\"\n",
    "    - \"How many units do you need?\"\n",
    "    - \"Please provide your delivery address.\"\n",
    "    \"\"\"\n",
    "\n",
    "    # Generate response using ChatGroq (Llama3-8B)\n",
    "    response = llm.invoke(prompt)\n",
    "\n",
    "    # Simulating user input (Replace with chatbot input in actual implementation)\n",
    "    user_input = input(f\"Agent: {response.content.strip()}\\nUser: \")\n",
    "\n",
    "    # Update order details dynamically\n",
    "    for key in order_details.keys():\n",
    "        if order_details[key] is None and user_input:\n",
    "            order_details[key] = user_input\n",
    "            break  # Update one field at a time\n",
    "\n",
    "    time.sleep(1)  # Simulate processing time\n",
    "\n",
    "print(\"\\n✅ Order Complete! Final Details:\")\n",
    "print(order_details)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating reusable module for order agent  (Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import requests\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "class OrderTakingAssistant:\n",
    "    def __init__(self, model_name=\"Llama3-8b-8192\"):\n",
    "        \"\"\"Initialize the order-taking assistant.\"\"\"\n",
    "        self.llm = ChatGroq(model_name=model_name)\n",
    "        self.order_details = {\n",
    "            \"product_name\": None,\n",
    "            \"Quantity_of_product\": None,\n",
    "            \"Address\": None,\n",
    "        }\n",
    "    \n",
    "    def is_order_complete(self):\n",
    "        \"\"\"Check if all required order details are provided.\"\"\"\n",
    "        return all(value is not None for value in self.order_details.values())\n",
    "\n",
    "    def get_missing_details_prompt(self):\n",
    "        \"\"\"Generate a prompt listing missing order details.\"\"\"\n",
    "        missing_fields = [key for key, value in self.order_details.items() if value is None]\n",
    "        return f\"The following details are missing: {', '.join(missing_fields)}. Please provide them one by one.\"\n",
    "    \n",
    "    def get_next_prompt(self):\n",
    "        \"\"\"Generate the next prompt based on missing details.\"\"\"\n",
    "        prompt = f\"\"\"\n",
    "        You are an order-taking assistant for a healthcare e-commerce system. \n",
    "        The user needs to place an order, but some details are missing. \n",
    "        {self.get_missing_details_prompt()}\n",
    "\n",
    "        Guidelines:\n",
    "        - Ask for the missing details step by step.\n",
    "        - If the user provides incomplete information, request clarification.\n",
    "        - Keep the conversation friendly and interactive.\n",
    "        - Don't try to greet the user again and again.\n",
    "\n",
    "        Example Response:\n",
    "        - \"What product would you like to order?\"\n",
    "        - \"How many units do you need?\"\n",
    "        - \"Please provide your delivery address.\"\n",
    "        \"\"\"\n",
    "        \n",
    "        # Generate response using ChatGroq (Llama3-8B)\n",
    "        try:\n",
    "            response = self.llm.invoke(prompt)\n",
    "            return response.content.strip()\n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\"\n",
    "    \n",
    "    def process_input(self, user_input):\n",
    "        \"\"\"Process user input and update order details.\"\"\"\n",
    "        for key in self.order_details.keys():\n",
    "            if self.order_details[key] is None and user_input:\n",
    "                self.order_details[key] = user_input\n",
    "                break  # Update one field at a time\n",
    "        \n",
    "        # Return the next prompt if order is not complete\n",
    "        if not self.is_order_complete():\n",
    "            return self.get_next_prompt()\n",
    "        else:\n",
    "            return \"Order complete! Thank you for providing all the details.\"\n",
    "    \n",
    "    def get_order_details(self):\n",
    "        \"\"\"Return the current order details.\"\"\"\n",
    "        return self.order_details\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset the order details.\"\"\"\n",
    "        self.order_details = {\n",
    "            \"product_name\": None,\n",
    "            \"Quantity_of_product\": None,\n",
    "            \"Address\": None,\n",
    "        }\n",
    "\n",
    "\n",
    "def get_next_prompt(self):\n",
    "    \"\"\"Generate the next prompt based on missing details.\"\"\"\n",
    "    # Get current state of the order\n",
    "    missing_fields = [key for key, value in self.order_details.items() if value is None]\n",
    "    first_missing = missing_fields[0] if missing_fields else None\n",
    "    \n",
    "    # Build context from existing details\n",
    "    filled_details = {k: v for k, v in self.order_details.items() if v is not None}\n",
    "    context = \"\"\n",
    "    if filled_details:\n",
    "        context = \"So far you've provided:\\n\" + \"\\n\".join([f\"- {k.replace('_', ' ').title()}: {v}\" for k, v in filled_details.items()])\n",
    "    \n",
    "    # Field-specific instructions\n",
    "    field_instructions = {\n",
    "        \"product_name\": \"Please provide the exact name of the healthcare product you want to order. Be specific about brand, model, and specifications if applicable.\",\n",
    "        \"Quantity_of_product\": \"Please specify the quantity needed as a number. If you need multiple sizes or variations, please indicate the quantity for each.\",\n",
    "        \"Address\": \"Please provide your complete delivery address including street address, city, state/province, postal code, and country.\"\n",
    "    }\n",
    "    \n",
    "    specific_instruction = field_instructions.get(first_missing, \"\") if first_missing else \"\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are an expert order-taking assistant for a healthcare e-commerce system with deep knowledge of medical products.\n",
    "    \n",
    "    CONTEXT:\n",
    "    - You are speaking directly to a healthcare customer\n",
    "    - Your sole purpose is to collect complete and accurate order information\n",
    "    - The user is trying to place an order, but you need {len(missing_fields)} more details\n",
    "    - {context}\n",
    "    \n",
    "    MISSING INFORMATION:\n",
    "    {self.get_missing_details_prompt()}\n",
    "    \n",
    "    NEXT REQUIREMENT:\n",
    "    {specific_instruction}\n",
    "    \n",
    "    GUIDELINES:\n",
    "    - Focus exclusively on collecting the NEXT missing field: {first_missing if first_missing else 'None'}\n",
    "    - Ask ONE clear, specific question to obtain the exact information needed\n",
    "    - If the user provides ambiguous or incomplete information, ask for clarification\n",
    "    - Validate information when possible (check if quantities are reasonable numbers, if addresses have all components)\n",
    "    - Acknowledge previous information provided before asking for new information\n",
    "    - Be concise but helpful - avoid unnecessary text\n",
    "    - DO NOT suggest specific products or make assumptions about what the user wants\n",
    "    - DO NOT generate fictional order information\n",
    "    - DO NOT ask for multiple pieces of information in a single response\n",
    "    \n",
    "    RESPONSE FORMAT:\n",
    "    - Brief acknowledgment of any information just provided (1 sentence maximum)\n",
    "    - A single clear question focusing only on the next missing detail\n",
    "    - Optional brief clarification of what format the information should be in (when applicable)\n",
    "    \n",
    "    EXAMPLE QUALITY RESPONSES:\n",
    "    - \"Thank you. What specific healthcare product would you like to order today? Please include brand and model if applicable.\"\n",
    "    - \"Got it. How many units of this item do you need? Please specify the quantity as a number.\"\n",
    "    - \"Thank you. Please provide your complete delivery address including street, city, state, and postal code.\"\n",
    "    \"\"\"\n",
    "    \n",
    "    # Generate response using ChatGroq (Llama3-8B)\n",
    "    try:\n",
    "        response = self.llm.invoke(prompt)\n",
    "        return response.content.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order Agnet without considering the edge cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: Thank you. What specific healthcare product would you like to order today? Please include brand and model if applicable.\n",
      "Agent: Thank you for confirming the product as Vit C. \n",
      "\n",
      "How many units of Vit C do you need? Please specify the quantity as a number.\n",
      "Agent: Here is my response:\n",
      "\n",
      "Thank you for ordering the Vit C product. Now, I need to confirm the quantity of the product you would like to order. Can you please specify the number of units you need?\n",
      "Agent: Thank you for providing the quantity of Vit C as 33. \n",
      "\n",
      "Can you please provide your complete delivery address including street address, city, state/province, postal code, and country?\n",
      "Agent: Thank you for providing the product name as \"Vit C\" and the quantity as 33. \n",
      "\n",
      "Please provide your complete delivery address including street, city, state/province, postal code, and country.\n",
      "Agent: Order complete! Thank you for providing all the details.\n",
      "\n",
      "✅ Order Complete! Final Details:\n",
      "{'product_name': 'vit c', 'Quantity_of_product': '33', 'Address': 'abc, pune'}\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import requests\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "class OrderTakingAssistant:\n",
    "    def __init__(self, model_name=\"Llama3-8b-8192\"):\n",
    "        \"\"\"Initialize the order-taking assistant.\"\"\"\n",
    "        self.llm = ChatGroq(model_name=model_name)\n",
    "        self.order_details = {\n",
    "            \"product_name\": None,\n",
    "            \"Quantity_of_product\": None,\n",
    "            \"Address\": None,\n",
    "        }\n",
    "    \n",
    "    def is_order_complete(self):\n",
    "        \"\"\"Check if all required order details are provided.\"\"\"\n",
    "        return all(value is not None for value in self.order_details.values())\n",
    "\n",
    "    def get_missing_details_prompt(self):\n",
    "        \"\"\"Generate a prompt listing missing order details.\"\"\"\n",
    "        missing_fields = [key for key, value in self.order_details.items() if value is None]\n",
    "        return f\"The following details are missing: {', '.join(missing_fields)}. Please provide them one by one.\"\n",
    "    \n",
    "    def get_next_prompt(self):\n",
    "        \"\"\"Generate the next prompt based on missing details.\"\"\"\n",
    "        # Get current state of the order\n",
    "        missing_fields = [key for key, value in self.order_details.items() if value is None]\n",
    "        first_missing = missing_fields[0] if missing_fields else None\n",
    "        \n",
    "        # Build context from existing details\n",
    "        filled_details = {k: v for k, v in self.order_details.items() if v is not None}\n",
    "        context = \"\"\n",
    "        if filled_details:\n",
    "            context = \"So far you've provided:\\n\" + \"\\n\".join([f\"- {k.replace('_', ' ').title()}: {v}\" for k, v in filled_details.items()])\n",
    "        \n",
    "        # Field-specific instructions\n",
    "        field_instructions = {\n",
    "            \"product_name\": \"Please provide the exact name of the healthcare product you want to order. Be specific about brand, model, and specifications if applicable.\",\n",
    "            \"Quantity_of_product\": \"Please specify the quantity needed as a number. If you need multiple sizes or variations, please indicate the quantity for each.\",\n",
    "            \"Address\": \"Please provide your complete delivery address including street address, city, state/province, postal code, and country.\"\n",
    "        }\n",
    "        \n",
    "        specific_instruction = field_instructions.get(first_missing, \"\") if first_missing else \"\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        You are an expert order-taking assistant for a healthcare e-commerce system with deep knowledge of medical products.\n",
    "        \n",
    "        CONTEXT:\n",
    "        - You are speaking directly to a healthcare customer\n",
    "        - Your sole purpose is to collect complete and accurate order information\n",
    "        - The user is trying to place an order, but you need {len(missing_fields)} more details\n",
    "        - {context}\n",
    "        \n",
    "        MISSING INFORMATION:\n",
    "        {self.get_missing_details_prompt()}\n",
    "        \n",
    "        NEXT REQUIREMENT:\n",
    "        {specific_instruction}\n",
    "        \n",
    "        GUIDELINES:\n",
    "        - Focus exclusively on collecting the NEXT missing field: {first_missing if first_missing else 'None'}\n",
    "        - Ask ONE clear, specific question to obtain the exact information needed\n",
    "        - If the user provides ambiguous or incomplete information, ask for clarification\n",
    "        - Validate information when possible (check if quantities are reasonable numbers, if addresses have all components)\n",
    "        - Acknowledge previous information provided before asking for new information\n",
    "        - Be concise but helpful - avoid unnecessary text\n",
    "        - DO NOT suggest specific products or make assumptions about what the user wants\n",
    "        - DO NOT generate fictional order information\n",
    "        - DO NOT ask for multiple pieces of information in a single response\n",
    "        \n",
    "        RESPONSE FORMAT:\n",
    "        - Brief acknowledgment of any information just provided (1 sentence maximum)\n",
    "        - A single clear question focusing only on the next missing detail\n",
    "        - Optional brief clarification of what format the information should be in (when applicable)\n",
    "        \n",
    "        EXAMPLE QUALITY RESPONSES:\n",
    "        - \"Thank you. What specific healthcare product would you like to order today? Please include brand and model if applicable.\"\n",
    "        - \"Got it. How many units of this item do you need? Please specify the quantity as a number.\"\n",
    "        - \"Thank you. Please provide your complete delivery address including street, city, state, and postal code.\"\n",
    "        \"\"\"\n",
    "        \n",
    "        # Generate response using ChatGroq (Llama3-8B)\n",
    "        try:\n",
    "            response = self.llm.invoke(prompt)\n",
    "            return response.content.strip()\n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\"\n",
    "    \n",
    "    def process_input(self, user_input):\n",
    "        \"\"\"Process user input and update order details.\"\"\"\n",
    "        for key in self.order_details.keys():\n",
    "            if self.order_details[key] is None and user_input:\n",
    "                self.order_details[key] = user_input\n",
    "                break  # Update one field at a time\n",
    "        \n",
    "        # Return the next prompt if order is not complete\n",
    "        if not self.is_order_complete():\n",
    "            return self.get_next_prompt()\n",
    "        else:\n",
    "            return \"Order complete! Thank you for providing all the details.\"\n",
    "    \n",
    "    def get_order_details(self):\n",
    "        \"\"\"Return the current order details.\"\"\"\n",
    "        return self.order_details\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset the order details.\"\"\"\n",
    "        self.order_details = {\n",
    "            \"product_name\": None,\n",
    "            \"Quantity_of_product\": None,\n",
    "            \"Address\": None,\n",
    "        }\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    assistant = OrderTakingAssistant()\n",
    "    \n",
    "    while not assistant.is_order_complete():\n",
    "        # Get the next prompt from the assistant\n",
    "        prompt = assistant.get_next_prompt()\n",
    "        print(f\"Agent: {prompt}\")\n",
    "        \n",
    "        # Simulate user input (replace with actual chatbot input in production)\n",
    "        user_input = input(\"User: \")\n",
    "        \n",
    "        # Process the user input\n",
    "        response = assistant.process_input(user_input)\n",
    "        print(f\"Agent: {response}\")\n",
    "    \n",
    "    # Display final order details\n",
    "    print(\"\\n✅ Order Complete! Final Details:\")\n",
    "    print(assistant.get_order_details())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi! I'm your healthcare order assistant. Let's get started with your order.\n",
      "Agent: Thank you. What specific healthcare product would you like to order today? Please include brand and model if applicable.\n",
      "Agent: Thank you for selecting Vit C as your product of interest. \n",
      "\n",
      "How many units of Vit C would you like to order? Please specify the quantity as a number.\n",
      "Agent: Here's my response:\n",
      "\n",
      "Thank you for choosing our healthcare e-commerce system! I'd like to confirm the quantity of Vit C you'd like to order. Could you please specify the quantity needed as a number?\n",
      "Agent: Thank you for providing the quantity of 55 of the Vit C product. Please provide your complete delivery address including street address, city, state/province, postal code, and country.\n",
      "Agent: Thank you for ordering Vit C in a quantity of 55. Now, I need to confirm your delivery address. Can you please provide the complete delivery address, including street address, city, state/province, postal code, and country?\n",
      "\n",
      "✅ Order Complete! Final Details:\n",
      "- Product Name: vit c\n",
      "- Quantity Of Product: 55\n",
      "- Address: ugygh\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import requests\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "class OrderTakingAssistant:\n",
    "    def __init__(self, model_name=\"Llama3-8b-8192\"):\n",
    "        \"\"\"Initialize the order-taking assistant.\"\"\"\n",
    "        self.llm = ChatGroq(model_name=model_name)\n",
    "        self.order_details = {\n",
    "            \"product_name\": None,\n",
    "            \"Quantity_of_product\": None,\n",
    "            \"Address\": None,\n",
    "        }\n",
    "    \n",
    "    def is_order_complete(self):\n",
    "        \"\"\"Check if all required order details are provided.\"\"\"\n",
    "        return all(value is not None for value in self.order_details.values())\n",
    "\n",
    "    def get_missing_details_prompt(self):\n",
    "        \"\"\"Generate a prompt listing missing order details.\"\"\"\n",
    "        missing_fields = [key for key, value in self.order_details.items() if value is None]\n",
    "        return f\"The following details are missing: {', '.join(missing_fields)}. Please provide them one by one.\"\n",
    "    \n",
    "    def get_next_prompt(self):\n",
    "        \"\"\"Generate the next prompt based on missing details.\"\"\"\n",
    "        # Get current state of the order\n",
    "        missing_fields = [key for key, value in self.order_details.items() if value is None]\n",
    "        first_missing = missing_fields[0] if missing_fields else None\n",
    "        \n",
    "        # Build context from existing details\n",
    "        filled_details = {k: v for k, v in self.order_details.items() if v is not None}\n",
    "        context = \"\"\n",
    "        if filled_details:\n",
    "            context = \"So far you've provided:\\n\" + \"\\n\".join([f\"- {k.replace('_', ' ').title()}: {v}\" for k, v in filled_details.items()])\n",
    "        \n",
    "        # Field-specific instructions\n",
    "        field_instructions = {\n",
    "            \"product_name\": \"Please provide the exact name of the healthcare product you want to order. Be specific about brand, model, and specifications if applicable.\",\n",
    "            \"Quantity_of_product\": \"Please specify the quantity needed as a number. If you need multiple sizes or variations, please indicate the quantity for each.\",\n",
    "            \"Address\": \"Please provide your complete delivery address including street address, city, state/province, postal code, and country.\"\n",
    "        }\n",
    "        \n",
    "        specific_instruction = field_instructions.get(first_missing, \"\") if first_missing else \"\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        You are an expert order-taking assistant for a healthcare e-commerce system with deep knowledge of medical products.\n",
    "        \n",
    "        CONTEXT:\n",
    "        - You are speaking directly to a healthcare customer\n",
    "        - Your sole purpose is to collect complete and accurate order information\n",
    "        - The user is trying to place an order, but you nebvved {len(missing_fields)} more details\n",
    "        - {context}\n",
    "        \n",
    "        MISSING INFORMATION:\n",
    "        {self.get_missing_details_prompt()}\n",
    "        \n",
    "        NEXT REQUIREMENT:\n",
    "        {specific_instruction}\n",
    "        \n",
    "        GUIDELINES:\n",
    "        - Focus exclusively on collecting the NEXT missing field: {first_missing if first_missing else 'None'}\n",
    "        - Ask ONE clear, specific question to obtain the exact information needed\n",
    "        - If the user provides ambiguous or incomplete information, ask for clarification\n",
    "        - Validate information when possible (check if quantities are reasonable numbers, if addresses have all components)\n",
    "        - Acknowledge previous information provided before asking for new information\n",
    "        - Be concise but helpful - avoid unnecessary text\n",
    "        - DO NOT suggest specific products or make assumptions about what the user wants\n",
    "        - DO NOT generate fictional order information\n",
    "        - DO NOT ask for multiple pieces of information in a single response\n",
    "        \n",
    "        RESPONSE FORMAT:\n",
    "        - Brief acknowledgment of any information just provided (1 sentence maximum)\n",
    "        - A single clear question focusing only on the next missing detail\n",
    "        - Optional brief clarification of what format the information should be in (when applicable)\n",
    "        \n",
    "        EXAMPLE QUALITY RESPONSES:\n",
    "        - \"Thank you. What specific healthcare product would you like to order today? Please include brand and model if applicable.\"\n",
    "        - \"Got it. How many units of this item do you need? Please specify the quantity as a number.\"\n",
    "        - \"Thank you. Please provide your complete delivery address including street, city, state, and postal code.\"\n",
    "        \"\"\"\n",
    "        \n",
    "        # Generate response using ChatGroq (Llama3-8B)\n",
    "        try:\n",
    "            response = self.llm.invoke(prompt)\n",
    "            return response.content.strip()\n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\"\n",
    "    \n",
    "    def process_input(self, user_input):\n",
    "        \"\"\"Process user input and update order details.\"\"\"\n",
    "        for key in self.order_details.keys():\n",
    "            if self.order_details[key] is None and user_input:\n",
    "                self.order_details[key] = user_input\n",
    "                break  # Update one field at a time\n",
    "        \n",
    "        # Return the next prompt if order is not complete\n",
    "        if not self.is_order_complete():\n",
    "            return self.get_next_prompt()\n",
    "        else:\n",
    "            return \"Order complete! Thank you for providing all the details.\"\n",
    "    \n",
    "    def get_order_details(self):\n",
    "        \"\"\"Return the current order details.\"\"\"\n",
    "        return self.order_details\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset the order details.\"\"\"\n",
    "        self.order_details = {\n",
    "            \"product_name\": None,\n",
    "            \"Quantity_of_product\": None,\n",
    "            \"Address\": None,\n",
    "        }\n",
    "\n",
    "# Example usage\n",
    "# if __name__ == \"__main__\":\n",
    "#     assistant = OrderTakingAssistant()\n",
    "    \n",
    "#     while not assistant.is_order_complete():\n",
    "#         # Get the next prompt from the assistant\n",
    "#         prompt = assistant.get_next_prompt()\n",
    "#         print(f\"Agent: {prompt}\")\n",
    "        \n",
    "#         # Simulate user input (replace with actual chatbot input in production)\n",
    "#         user_input = input(\"User: \")\n",
    "#         print(f\"User: {user_input}\")\n",
    "        \n",
    "#         # Process the user input\n",
    "#         response = assistant.process_input(user_input)\n",
    "#         print(f\"Agent: {response}\")\n",
    "    \n",
    "#     # Display final order details\n",
    "#     print(\"\\n✅ Order Complete! Final Details:\")\n",
    "#     print(assistant.get_order_details())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    assistant = OrderTakingAssistant()\n",
    "    \n",
    "    print(\"Hi! I'm your healthcare order assistant. Let's get started with your order.\")\n",
    "    \n",
    "    while not assistant.is_order_complete():\n",
    "        # Get the next prompt from the assistant\n",
    "        prompt = assistant.get_next_prompt()\n",
    "        print(f\"Agent: {prompt}\")\n",
    "        \n",
    "        # Simulate user input (replace with actual chatbot input in production)\n",
    "        user_input = input(\"User: \")\n",
    "        \n",
    "        # Process the user input and get the assistant's response\n",
    "        response = assistant.process_input(user_input)\n",
    "        \n",
    "        # Print the assistant's response only if the order is not complete\n",
    "        if not assistant.is_order_complete():\n",
    "            print(f\"Agent: {response}\")\n",
    "    \n",
    "    # Display final order details\n",
    "    print(\"\\n✅ Order Complete! Final Details:\")\n",
    "    for key, value in assistant.get_order_details().items():\n",
    "        print(f\"- {key.replace('_', ' ').title()}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatGroq(model_name=\"llama-3.1-8b-instant\")\n",
    "\n",
    "available_products = [\n",
    "            \"Paracetamol\", \n",
    "            \"Ibuprofen\", \n",
    "            \"Digital Thermometer\", \n",
    "            \"Blood Pressure Monitor\", \n",
    "            \"Glucose Test Strips\", \n",
    "            \"First Aid Kit\", \n",
    "            \"Hand Sanitizer\", \n",
    "            \"Face Masks N95\", \n",
    "            \"Vitamin D Supplements\", \n",
    "            \"Elastic Bandage\",\n",
    "            \"Aspirin\",\n",
    "            \"Insulin Syringes\",\n",
    "            \"Stethoscope\",\n",
    "            \"Pulse Oximeter\",\n",
    "            \"Heating Pad\"\n",
    "        ]\n",
    "\n",
    "def validate(assistant_res, user_input):\n",
    "    prompt = f\"\"\"\n",
    "    Your task is to validate the user responce based on the following scenarios:\n",
    "    1st case: {assistant_res} is related to the product name.\n",
    "    - check if {user_input} product is available in the list {available_products}\n",
    "    - return answer as \"'product_name': None\" in json format.\n",
    "\n",
    "    2nd case: {assistant_res} is related to the address.\n",
    "    - Check if the {user_input} is a valid address format.\n",
    "    - for example it should contain city, state, postal code \n",
    "    - postal code should be a valid number and should be of 6 digits.\n",
    "    - return answer as \"'Address': None\" in json format.\n",
    "\n",
    "    produce the following output without any additions, not a single letter outside of the structure bellow.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    return response.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```python\n",
      "import re\n",
      "import json\n",
      "\n",
      "def validate_product(user_response):\n",
      "    product_list = ['Paracetamol', 'Ibuprofen', 'Digital Thermometer', 'Blood Pressure Monitor', 'Glucose Test Strips', 'First Aid Kit', 'Hand Sanitizer', 'Face Masks N95', 'Vitamin D Supplements', 'Elastic Bandage', 'Aspirin', 'Insulin Syringes', 'Stethoscope', 'Pulse Oximeter', 'Heating Pad']\n",
      "    \n",
      "    if \"Dolo\" in user_response:\n",
      "        if user_response.replace(\"Dolo\", \"\").strip() in product_list:\n",
      "            return json.dumps({'product_name': None})\n",
      "        else:\n",
      "            return json.dumps({'product_name': \"Product not found\"})\n",
      "    else:\n",
      "        return json.dumps({'product_name': \"No product mentioned\"})\n",
      "\n",
      "def validate_address(user_response):\n",
      "    address_pattern = r\"(.*)\\, (.*)\\, (\\d{6})\"\n",
      "    if re.match(address_pattern, user_response):\n",
      "        return json.dumps({'Address': None})\n",
      "    else:\n",
      "        return json.dumps({'Address': \"Invalid address format\"})\n",
      "\n",
      "def main():\n",
      "    user_response = input(\"Enter your response: \")\n",
      "    \n",
      "    if \"specific healthcare product\" in user_response:\n",
      "        if \"Thank you\" in user_response:\n",
      "            if \"order today\" in user_response:\n",
      "                print(validate_product(user_response))\n",
      "            else:\n",
      "                print(json.dumps({'product_name': \"Order not specified\"}))\n",
      "        else:\n",
      "            print(json.dumps({'product_name': \"Thank you not found\"}))\n",
      "    elif \"Thank you\" in user_response and \"order today\" in user_response:\n",
      "        print(validate_address(user_response))\n",
      "    else:\n",
      "        print(json.dumps({'product_name': \"Invalid response\"}))\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "```\n",
      "\n",
      "This code has three functions: `validate_product`, `validate_address`, and `main`. The `main` function takes the user's response as input and calls the respective validation function based on the input. The `validate_product` function checks if the product name is in the list of available products and returns a JSON response accordingly. The `validate_address` function checks if the address is in the valid format and returns a JSON response accordingly.\n"
     ]
    }
   ],
   "source": [
    "assistant_res = \"Thank you. What specific healthcare product would you like to order today? Please include brand and model if applicable.\"\n",
    "user_input = \"dolo\"\n",
    "\n",
    "a = validate(assistant_res, user_input)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Order agent by considering EDGE CASES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: I'm happy to help you with your order!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import requests\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "class OrderTakingAssistant:\n",
    "    def __init__(self, model_name=\"Llama3-8b-8192\"):\n",
    "        \"\"\"Initialize the order-taking assistant.\"\"\"\n",
    "        self.llm = ChatGroq(model_name=model_name)\n",
    "        self.order_details = {\n",
    "            \"product_name\": None,\n",
    "            \"Quantity_of_product\": None,\n",
    "            \"Address\": None,\n",
    "        }\n",
    "    \n",
    "    def is_order_complete(self):\n",
    "        \"\"\"Check if all required order details are provided.\"\"\"\n",
    "        return all(value is not None for value in self.order_details.values())\n",
    "\n",
    "    def get_missing_details_prompt(self):\n",
    "        \"\"\"Generate a prompt listing missing order details.\"\"\"\n",
    "        missing_fields = [key for key, value in self.order_details.items() if value is None]\n",
    "        return f\"The following details are missing: {', '.join(missing_fields)}. Please provide them one by one.\"\n",
    "    \n",
    "    def get_next_prompt(self):\n",
    "        \"\"\"Generate the next prompt based on missing details.\"\"\"\n",
    "        # Get current state of the order\n",
    "        missing_fields = [key for key, value in self.order_details.items() if value is None]\n",
    "        first_missing = missing_fields[0] if missing_fields else None\n",
    "        \n",
    "        # Build context from existing details\n",
    "        filled_details = {k: v for k, v in self.order_details.items() if v is not None}\n",
    "        context = \"\"\n",
    "        if filled_details:\n",
    "            context = \"So far you've provided:\\n\" + \"\\n\".join([f\"- {k.replace('_', ' ').title()}: {v}\" for k, v in filled_details.items()])\n",
    "        \n",
    "        # Field-specific instructions\n",
    "        field_instructions = {\n",
    "            \"product_name\": \"Please provide the exact name of the healthcare product you want to order. Be specific about brand, model, and specifications if applicable.\",\n",
    "            \"Quantity_of_product\": \"Please specify the quantity needed as a number. If you need multiple sizes or variations, please indicate the quantity for each.\",\n",
    "            \"Address\": \"Please provide your complete delivery address including street address, city, state/province, postal code, and country.\"\n",
    "        }\n",
    "        \n",
    "        specific_instruction = field_instructions.get(first_missing, \"\") if first_missing else \"\"\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        You are an expert order-taking assistant for a healthcare e-commerce system with deep knowledge of medical products.\n",
    "        \n",
    "        CONTEXT:\n",
    "        - You are speaking directly to a healthcare customer\n",
    "        - Your sole purpose is to collect complete and accurate order information\n",
    "        - The user is trying to place an order, but you need {len(missing_fields)} more details\n",
    "        - {context}\n",
    "        \n",
    "        MISSING INFORMATION:\n",
    "        {self.get_missing_details_prompt()}\n",
    "        \n",
    "        NEXT REQUIREMENT:\n",
    "        {specific_instruction}\n",
    "        \n",
    "        GUIDELINES:\n",
    "        - Focus exclusively on collecting the NEXT missing field: {first_missing if first_missing else 'None'}\n",
    "        - Ask ONE clear, specific question to obtain the exact information needed\n",
    "        - If the user provides ambiguous or incomplete information, ask for clarification\n",
    "        - Validate information when possible (check if quantities are reasonable numbers, if addresses have all components)\n",
    "        - Acknowledge previous information provided before asking for new information\n",
    "        - Be concise but helpful - avoid unnecessary text\n",
    "        - DO NOT suggest specific products or make assumptions about what the user wants\n",
    "        - DO NOT generate fictional order information\n",
    "        - DO NOT ask for multiple pieces of information in a single response\n",
    "        \n",
    "        RESPONSE FORMAT:\n",
    "        - Brief acknowledgment of any information just provided (1 sentence maximum)\n",
    "        - A single clear question focusing only on the next missing detail\n",
    "        - Optional brief clarification of what format the information should be in (when applicable)\n",
    "        \n",
    "        EXAMPLE QUALITY RESPONSES:\n",
    "        - \"Thank you. What specific healthcare product would you like to order today? Please include brand and model if applicable.\"\n",
    "        - \"Got it. How many units of this item do you need? Please specify the quantity as a number.\"\n",
    "        - \"Thank you. Please provide your complete delivery address including street, city, state, and postal code.\"\n",
    "        \"\"\"\n",
    "        \n",
    "        # Generate response using ChatGroq (Llama3-8B)\n",
    "        try:\n",
    "            response = self.llm.invoke(prompt)\n",
    "            return response.content.strip()\n",
    "        except Exception as e:\n",
    "            return f\"Error: {str(e)}\"\n",
    "    \n",
    "    def process_input(self, user_input):\n",
    "        \"\"\"Process user input and update order details.\"\"\"\n",
    "        for key in self.order_details.keys():\n",
    "            if self.order_details[key] is None and user_input:\n",
    "                self.order_details[key] = user_input\n",
    "                break  # Update one field at a time\n",
    "        \n",
    "        # Return the next prompt if order is not complete\n",
    "        if not self.is_order_complete():\n",
    "            return self.get_next_prompt()\n",
    "        else:\n",
    "            return \"Order complete! Thank you for providing all the details.\"\n",
    "    \n",
    "    def get_order_details(self):\n",
    "        \"\"\"Return the current order details.\"\"\"\n",
    "        return self.order_details\n",
    "    \n",
    "    def reset(self):\n",
    "        \"\"\"Reset the order details.\"\"\"\n",
    "        self.order_details = {\n",
    "            \"product_name\": None,\n",
    "            \"Quantity_of_product\": None,\n",
    "            \"Address\": None,\n",
    "        }\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    assistant = OrderTakingAssistant()\n",
    "    \n",
    "    while not assistant.is_order_complete():\n",
    "        # Get the next prompt from the assistant\n",
    "        prompt = assistant.get_next_prompt()\n",
    "        print(f\"Agent: {prompt}\")\n",
    "        \n",
    "        # Simulate user input (replace with actual chatbot input in production)\n",
    "        user_input = input(\"User: \")\n",
    "        \n",
    "        # Process the user input\n",
    "        response = assistant.process_input(user_input)\n",
    "        print(f\"Agent: {response}\")\n",
    "    \n",
    "    # Display final order details\n",
    "    print(\"\\n✅ Order Complete! Final Details:\")\n",
    "    print(assistant.get_order_details())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6) Summurization Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.03136897087097168, 0.037830572575330734, 0.07630812376737595]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import getpass\n",
    "\n",
    "inference_api_key = \"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\"\n",
    "\n",
    "from langchain_community.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "\n",
    "embeddings = HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=inference_api_key, model_name=\"sentence-transformers/all-MiniLM-l6-v2\"\n",
    ")\n",
    "\n",
    "text = \"how are you\"\n",
    "query_result = embeddings.embed_query(text)\n",
    "query_result[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mayur\\AppData\\Local\\Temp\\ipykernel_23244\\3309466584.py:16: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
      "C:\\Users\\mayur\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\mayur\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import SentenceTransformerEmbeddings\n",
    "from langchain_chroma import Chroma\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_groq import ChatGroq\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "llm = ChatGroq(model_name=\"Llama3-8b-8192\")\n",
    "\n",
    "db_path = \"C:/Users/mayur/Desktop/FRACSNET/RAG_tech_comparisons/test_db\"\n",
    "\n",
    "\n",
    "def load_vectordb():\n",
    "    embedding = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "    loaded_db = Chroma(persist_directory=db_path, embedding_function=embedding)\n",
    "    return loaded_db\n",
    "    \n",
    "vectordb = load_vectordb()\n",
    "\n",
    "\n",
    "def summarize_document(vectordb, topic, llm, max_docs=5):\n",
    "\n",
    "    template = \"\"\"Based on the following document excerpts, generate a concise and accurate pointwise summary about the topic: {question}\n",
    "\n",
    "    DOCUMENT EXCERPTS:\n",
    "    {context}\n",
    "\n",
    "    Instructions:\n",
    "    - Extract key insights and main points directly related to the topic.\n",
    "    - Present the summary in a clear, structured, and pointwise format.\n",
    "    - Ensure accuracy by only using information from the excerpts.\n",
    "    - Keep each point brief yet informative.\n",
    "    - Avoid unnecessary details or repetition.\n",
    "\n",
    "    ### SUMMARY:\n",
    "    \"\"\"\n",
    "\n",
    "    SUMMARIZATION_PROMPT = PromptTemplate(\n",
    "        input_variables=[\"context\", \"question\"], \n",
    "        template=template\n",
    "    )\n",
    "\n",
    "    # Adjust retriever to get more documents for a comprehensive summary\n",
    "    retriever = vectordb.as_retriever(search_kwargs={\"k\": max_docs})\n",
    "    \n",
    "    # Use the RetrievalQA chain with our summarization prompt\n",
    "    summary_chain = RetrievalQA.from_chain_type(\n",
    "        llm, \n",
    "        retriever=retriever, \n",
    "        return_source_documents=True, \n",
    "        chain_type_kwargs={\"prompt\": SUMMARIZATION_PROMPT}\n",
    "    )\n",
    "\n",
    "    result = summary_chain.invoke(topic)\n",
    "    return result[\"result\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is a concise and accurate pointwise summary about Drug-Induced Nutrient Depletion (DIND):\n",
      "\n",
      "**What is DIND?**\n",
      "\n",
      "* Common prescription medications can impact nutrient status and lead to deficiencies.\n",
      "* Over time, these deficiencies can cause further health concerns.\n",
      "\n",
      "**Common Cardiometabolic Drugs and Nutrient Depletions:**\n",
      "\n",
      "* Cardiac glycosides (e.g., Lanoxicaps, Lanoxin, Crystodigin): deplete calcium, magnesium, phosphate, and thiamine.\n",
      "* Beta blockers (e.g., Tenormin, Cardicor, Betaloc, Lopresor): deplete coenzyme Q10 and melatonin.\n",
      "* Thiazide diuretics: deplete coenzyme Q10, magnesium, phosphate, potassium, sodium, and zinc.\n",
      "* Loop diuretics: deplete calcium, magnesium, potassium, pyridoxine, sodium, thiamine, and vitamin C.\n",
      "* ACE inhibitors: deplete sodium and zinc.\n",
      "* Statins: deplete carnitine, copper, coenzyme Q10, essential fatty acids, selenium, vitamin D, vitamin E, and zinc.\n",
      "* Metformin: depletes coenzyme Q10, folic acid, and vitamin B12.\n",
      "\n",
      "**Vitamin D:**\n",
      "\n",
      "* Important for bone health, calcium absorption, and overall health.\n",
      "* Deficiency is widespread and can lead to various health issues.\n",
      "* Available in capsules or liquid form, with recommended daily intake varying from 1,000 IU to 5,000 IU.\n",
      "\n",
      "**Core Support:**\n",
      "\n",
      "* A supplement designed to support liver detoxification and toxin elimination.\n",
      "* Contains a blend of fiber, amino acids, and other nutrients to promote detoxification and elimination.\n",
      "* Available in French Vanilla and Chocolate flavors.\n",
      "\n",
      "I hope this summary meets your requirements! Let me know if you need any further assistance.\n"
     ]
    }
   ],
   "source": [
    "# Example usage for summarization\n",
    "topic = \"Give me short summary about Drug-Induced Nutrient Depletion (DIND)\"\n",
    "summary = summarize_document(vectordb, topic, llm, max_docs=5)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables: []\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Postgres DB Connection\n",
    "\n",
    "# Host:k4m2a.postgres.database.azure.com\n",
    "# Port=5432\n",
    "# Username=postgres\n",
    "# Password=Mangoman@123\n",
    "# Database=postgres\n",
    "# Schema Name : k4m2a\n",
    "\n",
    "conn = psycopg2.connect(\n",
    "    host=\"k4m2a.postgres.database.azure.com\",\n",
    "    port=5432,\n",
    "    database=\"postgres\",\n",
    "    user=\"postgres\",\n",
    "    password=\"Mangoman@123\"\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SET search_path TO k4m2a;\")\n",
    "cursor.execute(\"SELECT table_name FROM information_schema.tables WHERE table_schema = 'k4m2a';\")\n",
    "tables = cursor.fetchall()\n",
    "\n",
    "print(\"Tables:\", tables)\n",
    "\n",
    "cursor.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
